[{"categories":["2025","serverless","serving"],"content":"Previously, while working on Serverless model inference Modelz, although we have pivoted now, I still want to share how to optimize the cold start problem of model inference. Since our service is based on container orchestration, it also involves the cold start problem of containers. Optimizing Model Inference Cold Start ","date":"2025-01-08","objectID":"/en/improve-model-serving-cold-start/:0:0","tags":["serving","cold start","inference"],"title":"Optimizing Model Inference Cold Start","uri":"/en/improve-model-serving-cold-start/"},{"categories":["2025","serverless","serving"],"content":"Problem First, let's look at the process of Serverless model inference, from user request to model inference: Click me sequenceDiagram participant User participant Cloudflare participant Ingress participant AutoScaler participant Node participant containerd User-\u003e\u003eCloudflare: Model Call Cloudflare-\u003e\u003eIngress: Request Ingress-\u003e\u003eAutoScaler: Request AutoScaler-\u003e\u003eNode: Scale Up Node-\u003e\u003econtainerd: Container Note right of containerd: 1. Pull Image \u003cbr\u003e2. Start Container\u003cbr\u003e3. Download model The entire process chain is very long, but the real time-consuming part is the process of pulling the image and starting the container by Containerd at the end. We further break down this part, and the time for each stage here is roughly from reference 1: Click me flowchart TD subgraph Pod Create 3A[Pull Image 3.5GB 140s] --\u003e 3B[Download Model] end subgraph GPU Node Provision 2A[VM Create 40s] --\u003e 2B[Node Initialize 45s] 2B --\u003e 2C[GPU Driver Install 25s] end subgraph AutoScaler 1A[HPA reaction 10s] --\u003e 1B[Auto Provisioning reaction 30s] --\u003e 1C[Node auto-scaling 35s] end If it is a 30G image (not uncommon in AI inference scenarios), the pull time will exceed 15 minutes, which is unacceptable for users. The model download depends on the size of the model and whether the model already exists in the Pod. This time is also uncontrollable, but we will propose targeted optimization solutions later. ","date":"2025-01-08","objectID":"/en/improve-model-serving-cold-start/:1:0","tags":["serving","cold start","inference"],"title":"Optimizing Model Inference Cold Start","uri":"/en/improve-model-serving-cold-start/"},{"categories":["2025","serverless","serving"],"content":"Deep Dive ","date":"2025-01-08","objectID":"/en/improve-model-serving-cold-start/:2:0","tags":["serving","cold start","inference"],"title":"Optimizing Model Inference Cold Start","uri":"/en/improve-model-serving-cold-start/"},{"categories":["2025","serverless","serving"],"content":"Why is the image so large? From the above two images, we can see that Except for the NVIDIA Kernel Driver and CUDA Lib placed on the Host, the libraries that AI applications and frameworks depend on are all placed in the image. NVIDIA's strategy prevents you from significantly reducing your image size. You don't know which libraries will be used, so you have to put all the libraries in the image. ","date":"2025-01-08","objectID":"/en/improve-model-serving-cold-start/:2:1","tags":["serving","cold start","inference"],"title":"Optimizing Model Inference Cold Start","uri":"/en/improve-model-serving-cold-start/"},{"categories":["2025","serverless","serving"],"content":"Solutions we have tried ","date":"2025-01-08","objectID":"/en/improve-model-serving-cold-start/:3:0","tags":["serving","cold start","inference"],"title":"Optimizing Model Inference Cold Start","uri":"/en/improve-model-serving-cold-start/"},{"categories":["2025","serverless","serving"],"content":"1. Preheating First, we use cluster-proportional-autoscaler to scale the GPU resources to 2 nodes when the total number of nodes is 8, even if there are no requests, there is a reserved bubble. Then, according to the frequency of image usage, we use kube-fledged to create an ImageCache on these nodes, so that when the actual request comes, the image is already on the node. ","date":"2025-01-08","objectID":"/en/improve-model-serving-cold-start/:3:1","tags":["serving","cold start","inference"],"title":"Optimizing Model Inference Cold Start","uri":"/en/improve-model-serving-cold-start/"},{"categories":["2025","serverless","serving"],"content":"2. Cache Model We developed a HuggingFace model caching service. This service compares the hash value of the model when the model is called. If the model already exists in the caching service, it directly returns the cached model; otherwise, it downloads the model to the caching service. ","date":"2025-01-08","objectID":"/en/improve-model-serving-cold-start/:3:2","tags":["serving","cold start","inference"],"title":"Optimizing Model Inference Cold Start","uri":"/en/improve-model-serving-cold-start/"},{"categories":["2025","serverless","serving"],"content":"3. GCP Image Streaming Use GCP Image Streaming to convert self-managed images or user-defined images to GCP's Artifact Registry. When the node pulls the image, it mounts the container layers to the node through the network, making containerd think the image is already on the node. However, this solution has several drawbacks: Requires GCP support, vendor lock-in User images need to be proxy converted to GCP, which will have some delay Although the pod is running, it is not fully operational, which may cause slow runtime ","date":"2025-01-08","objectID":"/en/improve-model-serving-cold-start/:3:3","tags":["serving","cold start","inference"],"title":"Optimizing Model Inference Cold Start","uri":"/en/improve-model-serving-cold-start/"},{"categories":["2025","serverless","serving"],"content":"4. Change Image Format Convert the OCI image format to nydus format and combine it with lazy pulling technology zran. Testing shows several times improvement. However, it requires modifying containerd configuration to support nydus. Combined with Dragonfly P2P technology, the image pull speed can be further improved. ","date":"2025-01-08","objectID":"/en/improve-model-serving-cold-start/:3:4","tags":["serving","cold start","inference"],"title":"Optimizing Model Inference Cold Start","uri":"/en/improve-model-serving-cold-start/"},{"categories":["2025","serverless","serving"],"content":"5. Use JuiceFS to Build Model Cache Cluster By building an independent cache pool, cache the model to JuiceFS. Mount the cache directory to the container through JuiceFS CSI. If the model already exists in JuiceFS, use it directly; if not, download and cache it directly to JuiceFS. This architecture mainly utilizes JuiceFS Posix and the advantages of using object storage, without worrying about cache size. Here, JuiceFS parameters need to be tuned, such as prefetch block, buffer size, etc. ","date":"2025-01-08","objectID":"/en/improve-model-serving-cold-start/:3:5","tags":["serving","cold start","inference"],"title":"Optimizing Model Inference Cold Start","uri":"/en/improve-model-serving-cold-start/"},{"categories":["2025","serverless","serving"],"content":"Possible Future Optimizations Use GCP's image preloading feature to preload images to the node through secondary boot disks. In-class registry cache spegel. Parallel Downloading in Kubelet KEP 3673. Parallel Container Layer Unpacking, mentioned in reference 1, containerd needs to implement high IO queue depth to fully utilize EBS throughput. yetone's solution: parsed the Dockerfile, then obtained the base image and a series of args, env, and commands, and merged them in order to hash as the s3 object key. Then, in the image builder job's pod container, started dind, then started a new container with the base image inside, executed the parsed commands, and after completion, tarred the container's rootfs, compressed it with zstd, and uploaded it to s3. OCI image builder and containerd remote snapshotter, on the builder side, build the image and split all layers into two layers: environment (very large) and code (very small). Then use pzstd and s5cmd for streaming compression and streaming upload to s3. On the snapshotter side, use s5cmd and pzstd for streaming download and streaming decompression, fully utilizing GKE's disk IO, improving image pull speed by about 4 times. Modal lazy container loading Do some research on ServerlessLLM OSDI24 ","date":"2025-01-08","objectID":"/en/improve-model-serving-cold-start/:4:0","tags":["serving","cold start","inference"],"title":"Optimizing Model Inference Cold Start","uri":"/en/improve-model-serving-cold-start/"},{"categories":["2025","serverless","serving"],"content":"References https://www.youtube.com/watch?v=e6Oo2aoZPnA https://www.youtube.com/watch?v=SlkEW4C2kd4 ","date":"2025-01-08","objectID":"/en/improve-model-serving-cold-start/:5:0","tags":["serving","cold start","inference"],"title":"Optimizing Model Inference Cold Start","uri":"/en/improve-model-serving-cold-start/"},{"categories":["2024","Postgres"],"content":"I've been researching PostgreSQL high availability solutions recently, and here's what I've learned. PostgreSQL High Availability ","date":"2024-07-26","objectID":"/en/postgres-ha/:0:0","tags":["High Availability","Postgres"],"title":"PostgreSQL High Availability","uri":"/en/postgres-ha/"},{"categories":["2024","Postgres"],"content":"High Availability Goals PostgreSQL high availability typically has two main objectives: RPO (Recovery Point Objective): The maximum acceptable amount of data loss measured in time. This represents how much data loss a business can tolerate. RTO (Recovery Time Objective): The maximum acceptable downtime, measured from when a disaster occurs until the system is operational again. This represents how quickly the system needs to be restored. In simple terms, this means determining how quickly to restore the database and to what state - for example, recovering within 5 minutes to a state no more than 30 minutes old. The ideal scenario would be RTO \u003c 30s and RPO ‚âà 0. ","date":"2024-07-26","objectID":"/en/postgres-ha/:1:0","tags":["High Availability","Postgres"],"title":"PostgreSQL High Availability","uri":"/en/postgres-ha/"},{"categories":["2024","Postgres"],"content":"Scenarios To achieve the ideal scenario mentioned above, the following situations need to be addressed: When the Primary node fails, automatic failover to the Standby node occurs within RTO requirements while meeting RPO goals. When accidental data deletion occurs, upgrade errors happen, or hardware failures occur, the ability to recover to a specific point in time. ","date":"2024-07-26","objectID":"/en/postgres-ha/:2:0","tags":["High Availability","Postgres"],"title":"PostgreSQL High Availability","uri":"/en/postgres-ha/"},{"categories":["2024","Postgres"],"content":"Concepts To handle these scenarios, the following technologies and concepts are essential: Continuous Archiving: Generally involves archiving WAL (Write Ahead Log) files; in case of database system crashes, recovery can be performed by replaying WAL. Point-in-Time Recovery (PITR): For hardware failures, high availability failover based on physical replication might be the best choice. For data corruption (whether machine or human error), Point-in-Time Recovery (PITR) is more appropriate as it provides a safety net for worst-case scenarios. Physical Replication: Complete replication of data files and transaction log files (PGData, pg_wals) Logical Replication: Replication between publisher and subscriber based on replication identifiers (e.g., primary keys), typically used for Foreign Data Wrapper (FDW) scenarios rather than disaster recovery. Streaming Replication: WAL log-based streaming replication, primarily used for disaster recovery. WAL XLOG records are continuously transmitted from primary to standby, available in both synchronous and asynchronous modes. ","date":"2024-07-26","objectID":"/en/postgres-ha/:3:0","tags":["High Availability","Postgres"],"title":"PostgreSQL High Availability","uri":"/en/postgres-ha/"},{"categories":["2024","Postgres"],"content":"Tools ","date":"2024-07-26","objectID":"/en/postgres-ha/:4:0","tags":["High Availability","Postgres"],"title":"PostgreSQL High Availability","uri":"/en/postgres-ha/"},{"categories":["2024","Postgres"],"content":"Backup and Restore Here are the common backup and recovery methods along with their pros and cons: 1. Pg_dump (Logical Backup) Logical backup exports database data to a file using the pg_dump SQL command, which can then be imported back using SQL commands. Advantages: Logical backups can be performed at table to database level as needed Backups don't block read/write activities on the database Can be restored to different major PostgreSQL versions and even different operating system architectures Disadvantages: Logical backups require replay during recovery, which can take considerable time for large datasets and may impact overall performance Doesn't support dumping global variables, requires pg_dumpall instead 2. Physical Backup Physical backup is an offline backup of the PostgreSQL cluster performed when the cluster is stopped, containing the entire cluster data. Advantages: Fast backup and recovery Suitable for large databases Ideal for high availability scenarios Disadvantages: Cannot restore across different versions Cannot restore across different operating systems 3. Continuous Archiving and Point-in-Time Recovery (PITR) Online Backup or Hot Backup starts with a full backup that can be performed online without stopping the PostgreSQL cluster. Incremental backups generate WAL logs, which can then be used for recovery through WAL archive replay. Advantages: Can recover to any point in time No application downtime required Disadvantages: May require significant time to recover data from archives, primarily used for massive databases that cannot be backed up frequently 4. Snapshots and Cloud Backups Snapshots require operating system or cloud provider support, with tools like rsync available for taking snapshots. Disadvantages: Not suitable when database tablespaces are stored across multiple drive volumes Several considerations go into backup planning, including frequency, storage location, recovery time, and retention policies. Here are some popular open-source tools to assist with backups: pgbackrest EDB barman WAL-G From this discussion, barman lacks some features compared to pgbackrest: Zstd compression Delta restore Encryption at rest Native postgres page checksum validation Multi repo ","date":"2024-07-26","objectID":"/en/postgres-ha/:4:1","tags":["High Availability","Postgres"],"title":"PostgreSQL High Availability","uri":"/en/postgres-ha/"},{"categories":["2024","Postgres"],"content":"High Availability Patroni Patroni uses asynchronous Streaming Replication by default, meaning transactions committed on the primary node may take some time to replicate to standby nodes. During this time, if the primary node fails, data from this period could be lost. Synchronous replication can be used to reduce data loss, but this affects primary node performance as it must wait for all standby nodes to receive and write WAL logs before committing transactions. A balance between availability and performance must be struck. Patroni's maximum_lag_on_failover and PostgreSQL's wal_segsize need to be balanced between availability and durability: maximum_lag_on_failover defaults to 1MB (1048576 bytes), meaning if a node lags beyond this value, it won't be chosen as the new primary. This typically works in conjunction with loop_wait and ttl parameters. For example, with a ttl of 30, if a Patroni node fails to renew with Etcd or Consul within 30 seconds, it loses leadership. With loop_wait set to 10 seconds, Patroni performs its main operation loop every 10 seconds, including status checks and necessary operations. Worst-case data loss: maximum_lag_on_failover bytes + logs written in the last TTL seconds. Reducing this value lowers the upper limit of data loss during failover but increases the chance of automatic failover being rejected due to unhealthy replicas (too far behind). wal_segsize parameter defines the size of each WAL log segment file, defaulting to 16MB ","date":"2024-07-26","objectID":"/en/postgres-ha/:4:2","tags":["High Availability","Postgres"],"title":"PostgreSQL High Availability","uri":"/en/postgres-ha/"},{"categories":["2024","Postgres"],"content":"Architecture There are many PostgreSQL high availability architectures available. Here are two common architectures, corresponding to self-hosted PostgreSQL and cloud-hosted PostgreSQL typical architectures: Pigsty Cloudnative-PG HA ","date":"2024-07-26","objectID":"/en/postgres-ha/:5:0","tags":["High Availability","Postgres"],"title":"PostgreSQL High Availability","uri":"/en/postgres-ha/"},{"categories":["2024","Postgres"],"content":"Pigsty HA Architecture The following diagram is from pigsty: From top to bottom: Application layer resolves DNS to vip-manager's VIP, vip-manager gets the current primary's IP address through etcd, then binds the L2 VIP to the primary node; HAProxy handles L5 layer port forwarding. Patroni: Synchronizes primary node information to etcd. vip-manager: Virtual IP and state managed synchronously by etcd. HAProxy: Routes based on ports 5433: Connects to PGBouncer pool for primary read/write 5434: Connects to PGBouncer pool for replica read-only 5436: Direct connection to primary for management 5438: Direct connection to replica for management, connects to dedicated replicas not handling online read traffic, used for ETL and analytical queries. Primary and replica synchronize WAL logs through Streaming Replication, primary sends WAL logs to replica via pg_receivexlog, replica replays WAL logs via pg_replay. Patroni performs backups through pgBackRest, backup data can be stored locally, in remote s3 or minio storage, refer to the documentation. PostgreSQL uses standard streaming replication to set up physical replicas, with replicas taking over when the primary fails. Patroni manages PostgreSQL server processes and handles high availability matters. Etcd provides distributed configuration storage (DCS) capability and is used for leader election after failures Patroni relies on Etcd to reach cluster leader consensus and provides health check interfaces. HAProxy exposes cluster services and automatically distributes traffic to healthy nodes using Patroni health check interfaces. vip-manager provides an optional layer 2 VIP, gets leader information from Etcd, and binds the VIP to the node hosting the cluster's primary. With primary-replica architecture + automatic failover + synchronous streaming replication + pgBackRest backup, RTO is within 1 minute and RPO is 0, meaning recovery within 1 minute with no data loss. ","date":"2024-07-26","objectID":"/en/postgres-ha/:5:1","tags":["High Availability","Postgres"],"title":"PostgreSQL High Availability","uri":"/en/postgres-ha/"},{"categories":["2024","Postgres"],"content":"Cloudnative-PG HA Architecture Based on Kubernetes container orchestration characteristics, Cloudnative-PG HA architecture adopts a more modern approach: Multi-region Kubernetes deployment PostgreSQL nodes deployed across multiple availability zones (three or more) Primary-Standby using synchronous or asynchronous Streaming Replication PostgreSQL instances don't share resources, have dedicated node resources, run on different Kubernetes worker nodes, use local volumes Application layer provides rw, ro, r services for connecting to primary node, hot standby replicas for read-only workloads, and any read-only workloads respectively; during failover, it automatically updates services to point to the promoted service, ensuring seamless traffic redirection from applications. Provides Pooler object to create PGBouncer connection pools for connecting to primary and read-only nodes Deploys PostgreSQL across multiple Kubernetes clusters through Replica Cluster Reduces global Recovery Point Objective (RPO) by storing PostgreSQL backup data across multiple locations, regions, and potentially different providers (disaster recovery) Reduces global Recovery Time Objective (RTO) by leveraging PostgreSQL replication outside the primary Kubernetes cluster (high availability) Designated primary cluster can be promoted at any time, making the replica cluster the primary cluster accepting write connections. WAL archiving through s3 Backups through barman, can backup to cloud object storage like s3 or use Volume Snapshot Under this architecture, cross-region disaster recovery provides approximately 5 minutes RPO at most, with synchronous Streaming Replication achieving 0 RPO and extremely low RTO. ","date":"2024-07-26","objectID":"/en/postgres-ha/:5:2","tags":["High Availability","Postgres"],"title":"PostgreSQL High Availability","uri":"/en/postgres-ha/"},{"categories":["2024","Postgres"],"content":"Supabase Backup graph TD; A(Supabase Backup)---\u003eB(Pro); B(Pro)---\u003eE(Database Size 0-40GB); B(Pro)---\u003eF(Database Size 40GB+); B(Pro)---\u003eG(PITR); B(Pro)---\u003eH(Read Replica); E(Database Size 0-40GB)---\u003eI(Logical Backup); F(Database Size 40GB+)---\u003eJ(Physical Backup); G(PITR)---\u003eJ(Physical Backup); H(Read Replica)---\u003eJ(Physical Backup); A(Supabase Backup)---\u003eC(Team); C(Team)---\u003eK(Database Size 0-40GB); C(Team)---\u003eL(Database Size 40GB+); C(Team)---\u003eM(PITR); C(Team)---\u003eN(Read Replica); K(Database Size 0-40GB)---\u003eI(Logical Backup); L(Database Size 40GB+)---\u003eJ(Physical Backup); M(PITR)---\u003eJ(Physical Backup); N(Read Replica)---\u003eJ(Physical Backup); A(Supabase Backup)---\u003eD(Enterprise); D(Enterprise)---\u003eO(Database Size 0-40GB); D(Enterprise)---\u003eP(Database Size 40GB+); D(Enterprise)---\u003eQ(PITR); D(Enterprise)---\u003eR(Read Replica); O(Database Size 0-40GB)---\u003eJ(Physical Backup); P(Database Size 40GB+)---\u003eJ(Physical Backup); Q(PITR)---\u003eJ(Physical Backup); R(Read Replica)---\u003eJ(Physical Backup); graph TD; A(Supabase Backup)--\u003eB(Pro); A(Supabase Backup)--\u003eC(Team); A(Supabase Backup)--\u003eD(Enterprise); B(Pro)--\u003eE(Daily Backup, Retain 7 days); E--\u003eH(pg_dumpall logical backupÔºå when database size \u003e 40GB will use physical backup); C(Team)--\u003eF(Daily Backup, Retain 2 weeks); F--\u003eH(pg_dumpall logical backupÔºå when database size \u003e 40GB will use physical backup); D(Enterprise)--\u003eG(Daily Backup, Retain 1 month); D--\u003eJ(physical backup); Users can access the daily generated logical backup SQL files for restore. graph TD; A(Supabase PITR)--\u003eB(WAL-G, archiving Write Ahead Log files, default 2 min or certain file size threshold and physical backups); B--\u003eC(2 minutes RPO); C--\u003eD(show database restore available from and latest restore available at); graph TD; A(PGVecto.rs Cloud PITR)--\u003eB(barman-cloud-wal-archive archiving Write Ahead Log files, default 5 min or certain file size threshold and barman-cloud-backup for physical backups); B--\u003eC(5 minutes RPO); C--\u003eD(show database restore available from and latest restore available at); D--\u003eE(delete cluster will delete all wal and physical backups); ","date":"2024-07-26","objectID":"/en/postgres-ha/:5:3","tags":["High Availability","Postgres"],"title":"PostgreSQL High Availability","uri":"/en/postgres-ha/"},{"categories":["2024","Postgres"],"content":"References https://pigsty.io/ https://cloudnative-pg.io/ https://www.cnblogs.com/xianghuaqiang/p/14792001.html https://docs.pgbarman.org/release/3.10.1/ https://github.com/cloudnative-pg/cloudnative-pg/discussions/3145 https://supabase.com/blog/postgresql-physical-logical-backups ","date":"2024-07-26","objectID":"/en/postgres-ha/:6:0","tags":["High Availability","Postgres"],"title":"PostgreSQL High Availability","uri":"/en/postgres-ha/"},{"categories":["2022","kubernetes","documentation"],"content":"Recently, I've been working on some NUMA-aware scheduling tasks on an internally developed platform, involving the discovery of Kubernetes node resource topology and scheduling. However, due to my limited knowledge, I often find myself struggling to grasp the full picture. This article is an attempt to summarize and organize my understanding. ","date":"2022-12-29","objectID":"/en/kubernetes-topo-aware-all-you-need-know/:0:0","tags":["kubernetes","topo aware"],"title":"All You Need to Know About Topology Awareness in Kubernetes","uri":"/en/kubernetes-topo-aware-all-you-need-know/"},{"categories":["2022","kubernetes","documentation"],"content":"Why Topology Awareness is Needed According to the official Kubernetes documentation, more and more systems are utilizing CPUs and hardware accelerators like GPUs and DPUs to support low-latency tasks and high-throughput parallel computing tasks. However, the explanation seems a bit unclear. The fundamental reason lies in the issues brought by the Von Neumann architecture. As the saying goes, there is no silver bullet. The Von Neumann architecture separates memory and processors, with both instructions and data stored in memory, laying the foundation for the universality of modern computing. However, it also poses a hidden risk: as memory capacity increases exponentially, data transfer between the CPU and memory becomes a bottleneck. Currently, most devices in servers are connected via high-speed PCIe buses, and the bus layout may vary depending on the server's purpose. As shown in the figure below (found online, not drawn by me), in the left diagram, GPUs reside in different PCIe domains, making direct P2P copying between GPU memories impossible. To copy memory from GPU 0 to GPU 2, it must first be copied via PCIe to the memory connected to CPU 0, then transferred to CPU 1 via QPI link, and finally transferred to GPU 2 via PCIe again. This process adds significant overhead in terms of latency and bandwidth, whereas the right diagram can achieve ultra-high-speed communication through GPU P2P connections. In summary, topology affects communication between devices, impacting business stability and efficiency, necessitating some technical means to make businesses topology-aware. PCIe Topo (figure 1) ","date":"2022-12-29","objectID":"/en/kubernetes-topo-aware-all-you-need-know/:1:0","tags":["kubernetes","topo aware"],"title":"All You Need to Know About Topology Awareness in Kubernetes","uri":"/en/kubernetes-topo-aware-all-you-need-know/"},{"categories":["2022","kubernetes","documentation"],"content":"Types of Topology Currently, the types of topology that need to be aware of include: GPU Topology Awareness NUMA Topology Awareness ","date":"2022-12-29","objectID":"/en/kubernetes-topo-aware-all-you-need-know/:2:0","tags":["kubernetes","topo aware"],"title":"All You Need to Know About Topology Awareness in Kubernetes","uri":"/en/kubernetes-topo-aware-all-you-need-know/"},{"categories":["2022","kubernetes","documentation"],"content":"GPU Topology Manager There are several implementation solutions in the industry: Volcano GPU Topology Awareness Baidu Intelligent Cloud GPU Topology-Aware Scheduling Volcano is not fully implemented yet, and Baidu's solution is closed-source, so we can only get a glimpse through shared information. Why Why is GPU topology awareness needed? Let's start with a diagram from NVIDIA, which describes the topology of the mainstream V100 GPU graphics card in servers. GPU Topo (figure 2) Each V100 GPU has 6 NVLink channels, and 8 GPUs cannot achieve full connectivity, with a maximum of 2 NVLink connections between 2 GPUs. For instance, there are 2 NVLink connections between GPU0 and GPU3, and between GPU0 and GPU4, while there is only one NVLink connection between GPU0 and GPU1, and no NVLink connection between GPU0 and GPU6. Therefore, communication between GPU0 and GPU6 still requires PCIe. The unidirectional communication bandwidth of NVLink is 25 GB/s, and the bidirectional bandwidth is 50 GB/s, while the communication bandwidth of PCIe is 16 GB/s. Thus, if GPUs are allocated incorrectly during GPU training, such as a training task Pod requesting two cards, GPU0 and GPU6, cross-GPU communication may become a bottleneck for the training task. Topology information can be viewed by executing the following command on a node: # nvidia-smi topo -m GPU0 GPU1 GPU2 GPU3 GPU4 GPU5 GPU6 GPU7 GPU0 X PIX PHB PHB SYS SYS SYS SYS GPU1 PIX X PHB PHB SYS SYS SYS SYS GPU2 PHB PHB X PIX SYS SYS SYS SYS GPU3 PHB PHB PIX X SYS SYS SYS SYS GPU4 SYS SYS SYS SYS X PIX PHB PHB GPU5 SYS SYS SYS SYS PIX X PHB PHB GPU6 SYS SYS SYS SYS PHB PHB X PIX GPU7 SYS SYS SYS SYS PHB PHB PIX X Legend: X = Self SYS = Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI) NODE = Connection traversing PCIe as well as the interconnect between PCIe Host Bridges within a NUMA node PHB = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU) PXB = Connection traversing multiple PCIe switches (without traversing the PCIe Host Bridge) PIX = Connection traversing a single PCIe switch NV# = Connection traversing a bonded set of # NVLinks How I won't parse it all here, as there isn't a complete implementation to look at. I'll outline some general ideas based on my understanding. The first step is awareness, which involves using a daemon component to gather information on NVIDIA GPUs, network topology, NVLink, and PCIe. The second step is the scheduler, which defines strategies. Strategy 1: Preferably schedule GPUs with the most NVLinks under the same NUMA node to a Pod; Strategy 2: Preferably allocate GPUs and network cards under the same PCI switch to the same Pod. The general process is as follows: GPU-device-plugin or other daemon processes construct the GPU topology information CRD for the node; The Pod defines a topology strategy, such as Strategy 1 or Strategy 2; The newly defined scheduler filters nodes that do not meet the strategy during the filter and priority phases and scores nodes that meet the strategy highly; The discovery and update of GPU devices on the node are handled by the device-plugin and kubelet, as referenced in this article. Currently, GPU topology information can be queried through the official nvml (NVIDIA Management Library) interface. ","date":"2022-12-29","objectID":"/en/kubernetes-topo-aware-all-you-need-know/:2:1","tags":["kubernetes","topo aware"],"title":"All You Need to Know About Topology Awareness in Kubernetes","uri":"/en/kubernetes-topo-aware-all-you-need-know/"},{"categories":["2022","kubernetes","documentation"],"content":"NUMA Topology Awareness Why When discussing NUMA topology awareness, it's essential to first explain what NUMA is and why it needs to be aware of it. NUMA Topo (figure 3) CPU Cache Latency (figure 4) The two figures above provide the answer. Modern CPUs often use the NUMA architecture, which stands for ‚ÄúNon-Uniform Memory Access.‚Äù Why use non-uniformity? Isn't uniformity better? The answer is no, because if UMA (Uniform Memory Access) is used, as the number of physical cores on the northbridge increases and CPU frequency rises, the bus bandwidth cannot keep up, and conflicts over accessing the same memory will become more severe. Returning to the NUMA architecture, each NUMA node has its own physical CPU cores, and the cores within each NUMA node also share the L3 Cache. Additionally, memory is distributed across each NUMA node. Some CPUs with hyper-threading enabled will present two logical cores for each physical CPU core in the operating system. From a business perspective, if programs run on the same NUMA node, they can better share some L3 Cache, which has a very fast access speed. If the L3 Cache is not hit, data can be read from memory, significantly reducing access speed. In today's container-dominated world, the issue of incorrect CPU allocation is particularly severe. Because nodes are now oversold, with many containers running simultaneously, what happens if the same process is allocated to different NUMA nodes: CPU contention leads to frequent context switching time; Frequent process switching causes CPU cache failures; Cross-NUMA memory access results in more severe performance bottlenecks. In summary, in modern CPU architectures, if NUMA topology relationships are not considered, incorrect CPU allocation can lead to performance issues, affecting business SLAs. How The previous section explained why NUMA-aware scheduling is needed. So how can NUMA topology be sensed, and what existing solutions are available? Here, I briefly list some projects in the Kubernetes ecosystem. If you have any additions, feel free to comment: Kubernetes Topology Manager Official Crane NUMA Topology Awareness Koordinator Fine-grained CPU Orchestration Kubernetes Topology Manager The Topology Manager is a kubelet component designed to coordinate a set of components responsible for these optimizations. The Topology Manager addresses a historical issue where the CPU Manager and Device Manager worked independently and were unaware of each other. Let's first look at the implementation of the Kubernetes Topology Manager. I don't want to reinvent the wheel here, so you can refer to a great article summarized by a colleague from Alibaba. Here's a summary: Find the topology hints for different resources, i.e., topology information. The CPU selection criteria prioritize the smallest number of NUMA nodes involved, with the smallest number of sockets involved as a secondary priority. The device manager prioritizes the smallest number of NUMA nodes involved while meeting resource requests. Merge hints from different topology types, i.e., union, to select the optimal strategy. If a selection is made, that's good. If not, what happens? Kubernetes provides kubelet configuration strategies: best-effort: The Kubernetes node will accept the Pod, but the effect may not meet expectations. restricted: The node will refuse to accept the Pod, and if the Pod is rejected, its status will become Terminated. single-NUMA-node: The node will refuse to accept the Pod, and if the Pod is rejected, its status will become Terminated. This is more restrictive than restricted, as the selected NUMA node count must be 1. Therefore, we see that the Kubernetes Topology Manager is still centered around NUMA, performing complete fair shortest path selection for different resources (NIC, GPU, CPU). Moreover, this process occurs after the Pod is scheduled to a specific node, which brings several issues: There is a high probability that the Pod will be Terminated, making it unusable","date":"2022-12-29","objectID":"/en/kubernetes-topo-aware-all-you-need-know/:2:2","tags":["kubernetes","topo aware"],"title":"All You Need to Know About Topology Awareness in Kubernetes","uri":"/en/kubernetes-topo-aware-all-you-need-know/"},{"categories":["2022","kubernetes","documentation"],"content":"References Standing on the shoulders of giants, thanks again. https://kubernetes.io/ https://github.com/volcano-sh/volcano/ https://mp.weixin.qq.com/s/uje27_MHBh8fMzWATusVwQ https://www.infoq.cn/article/tdfgiikxh9bcgknywl6s https://github.com/NVIDIA/go-nvml https://gocrane.io/docs/ https://koordinator.sh/docs/user-manuals https://www.likakuli.com/posts/kubernetes-kubelet-restart/ https://zhuanlan.zhihu.com/p/121588317 ","date":"2022-12-29","objectID":"/en/kubernetes-topo-aware-all-you-need-know/:3:0","tags":["kubernetes","topo aware"],"title":"All You Need to Know About Topology Awareness in Kubernetes","uri":"/en/kubernetes-topo-aware-all-you-need-know/"},{"categories":["2024","vector search","Postgres"],"content":"It has been over a year since I joined Tensorchord, and I haven't had the time to sit down and write some articles. Mainly because after having my daughter Tongtong, things have become much busier. During this time, I also experienced the pivot of the business from Serverless model inference Modelz to the vector search field VectorChord. The experience of this pivot might be shared in future articles, and those interested can also directly contact me. Recently, I have been developing VectorChord Cloud, so I am summarizing the ins and outs of vector databases while learning. ","date":"2024-07-13","objectID":"/en/vector-search/:0:0","tags":["vector search","Postgres"],"title":"The internals of Vector Databases","uri":"/en/vector-search/"},{"categories":["2024","vector search","Postgres"],"content":"1. What is a Vector The meaning of vectors in physics, mathematics, and computer science is different. Here, vectors mainly refer to vectors in computer science, which are an ordered set of numerical values. In computer science, vectors are usually used to represent data. For example, in machine learning, we usually convert an image into a vector or tokenize a piece of text and then convert it into a vector for training. In vector databases, we usually convert an image, a piece of text, or an audio segment into a vector through an embedding model and then store and retrieve it. Below is a simple example where we convert a piece of text into a vector using the all-MiniLM-L6-v2 model. all-MiniLM-L6-v2 maps sentences and paragraphs to a 384-dimensional dense vector and can be used for tasks such as clustering or semantic search. from sentence_transformers import SentenceTransformer model = SentenceTransformer('all-MiniLM-L6-v2') sentences = [ \"Hugging Face is creating a tool that democratizes AI.\", \"I love natural language processing.\", \"Transformers are state-of-the-art models for NLP tasks.\" ] # generate embeddings embeddings = model.encode(sentences) # print the embeddings for sentence, embedding in zip(sentences, embeddings): print(f\"Sentence: {sentence}\") print(f\"Embedding: {embedding}\\n\") In summary, vectors are actually the bridge between real-world entities and the computer world. Computers understand and process real-world data through vectors. ","date":"2024-07-13","objectID":"/en/vector-search/:1:0","tags":["vector search","Postgres"],"title":"The internals of Vector Databases","uri":"/en/vector-search/"},{"categories":["2024","vector search","Postgres"],"content":"2. What is a Vector Database The world originally did not have vector databases, but with more vectors, vector databases emerged, just kidding hh. Here I give a simple definition: a database that can index and store vectors to achieve fast retrieval and similarity search functions. Many people on the internet define vector databases as databases that focus on processing vector data, which is not accurate. To be precise, vectors and vector search are a new data type and query processing method, which is not fundamentally different from similar and indexing methods in traditional databases. ","date":"2024-07-13","objectID":"/en/vector-search/:2:0","tags":["vector search","Postgres"],"title":"The internals of Vector Databases","uri":"/en/vector-search/"},{"categories":["2024","vector search","Postgres"],"content":"3. What is Vector Search Vector search, also known as vector retrieval, is a technique in Information Retrieval used to find the most similar vectors to a given query vector in a high-dimensional vector space. To measure the similarity between two vectors, we usually use cosine similarity, Euclidean distance, Manhattan distance, etc. To speed up vector search, we usually use index structures such as KD-Tree, IVF (Inverted File Index), HNSW (Hierarchical Navigable Small World), etc. Vector search has applications in many fields, such as in recommendation systems, where we can use vector search to find products most similar to a user's historical behavior and then recommend them to the user; in image retrieval, we can use vector search to find images most similar to a given image; in RAG (Retrieval Augmented Generation), we can use vector search to find text most similar to a given question, enhancing the Context of large models to improve the quality of generated answers. ","date":"2024-07-13","objectID":"/en/vector-search/:3:0","tags":["vector search","Postgres"],"title":"The internals of Vector Databases","uri":"/en/vector-search/"},{"categories":["2024","vector search","Postgres"],"content":"3.1 Vector Search Application Scenarios 3.1.1 Recommendation System As in the On-premise case of Qdrant about Video Content-based Recommendation, the multilingual universal sentence encoder is used to embed the script when uploading a video. Here, it is not simply extracting frames from the video, but more information comes from the video title, description, automatically detected tags, and content recognized by Whisper speech recognition. So the current problem is that if the video has no audio, the title and description are forced to be used for recommendation, which is a big challenge for the review team. Here, the call start issues in the recommendation field are mentioned, that is, when users first start using the system, the recommendation quality of the recommendation system is not high, and the user experience is poor at this time. On the basis of non-real-time updated collaborative recommenders and metadata recommenders, adding a content-based recommender can greatly optimize call start issues. 3.1.2 Image Retrieval immich is a high-performance open-source self-hosted image and video management solution. Imagine when you upload all your videos and images to immich, it is difficult to find the image or video you want in a short time. At this time, an efficient image retrieval system smart search is needed. Through vector search technology, you can quickly and accurately find the image or video you want through text descriptions and additional filters (tags, dates, etc.). Images from immich 3.1.3 RAG RAG (Retrieval Augmented Generation) mainly solves several problems in LLM applications: The data used to train LLM models is not real-time, in other words, it is static data, and the cost of obtaining the latest data and retraining is too high. LLM lacks domain-specific knowledge because the training corpus of LLM is mostly general datasets on the internet. In fields such as finance, healthcare, and law, private data may be the most important, and the lack of domain data will cause LLM to hallucinate. The black box problem of LLM, we cannot know how LLM generates answers, and where the source of the answers comes from. Here, I borrow two diagrams from Paul lusztin and Aurimas Griciunas to explain how RAG works: Obtain streaming real-time data of financial news and historical data. Chunk the data into inputs for the embedding model, and then store the embeddings in the vector database. User asks a question. Find the most similar news chunks through vector search, and then perform Prompt composition with the user's historical chat information and news chunks. Input into the LLM to generate an answer. Return the answer to the user. Store the new chat information in the user's historical data. Private data, such as Notion, Jira, local PDF files, etc., are chunked into inputs for the embedding model. Input the chunks into the embedding model, and then store the embeddings in the vector database. The Vector Database builds an Index. User asks a question, input into the embedding model. The embedding model outputs the query's embedding vector. Use the vector from step 5 as the Query vector and input it into the vector database. The vector database finds the most similar chunks through ANNs (Approximate Nearest Neighbors Search). Construct a Prompt with the searched chunks and the query. Input into the LLM to generate an answer. ","date":"2024-07-13","objectID":"/en/vector-search/:3:1","tags":["vector search","Postgres"],"title":"The internals of Vector Databases","uri":"/en/vector-search/"},{"categories":["2024","vector search","Postgres"],"content":"3.2 Similarity Metrics Cosine similarity is a method used to measure the similarity between two vectors. It is measured by calculating the angle between two vectors. The range of cosine similarity is [-1, 1], where 1 means the angle between two vectors is 0 degrees, indicating that the two vectors are identical; -1 means the angle between two vectors is 180 degrees, indicating that the two vectors are completely opposite; 0 means the angle between two vectors is 90 degrees, indicating that there is no similarity between the two vectors. The calculation formula is as follows: This formula calculates the cosine value of the angle between vectors ùê¥ and ùêµ. Euclidean distance is a method used to measure the similarity between two vectors. It is measured by calculating the distance between two vectors. The range of Euclidean distance is [0, ‚àû], where 0 means the two vectors are identical, and the larger the value, the greater the difference between the two vectors. The calculation formula is as follows: This formula calculates the Euclidean distance between vectors ùê¥ and ùêµ. Some do not take the square root, which only changes the numerical value but does not fundamentally differ. Negative inner product is measured by calculating the inner product between two vectors. The larger the value, the higher the similarity between the two vectors. The calculation formula is as follows: Manhattan distance (taxicab distance) is measured by calculating the distance between two vectors. The range of Manhattan distance is [0, ‚àû], where 0 means the two vectors are identical, and the larger the value, the greater the difference between the two vectors. The calculation formula is as follows: ","date":"2024-07-13","objectID":"/en/vector-search/:3:2","tags":["vector search","Postgres"],"title":"The internals of Vector Databases","uri":"/en/vector-search/"},{"categories":["2024","vector search","Postgres"],"content":"3.3 Vector Search Algorithms Intuitively, we can find the vector most similar to a given query vector by traversing all vectors, but the time complexity of this method is O(n), which is not feasible when the number of vectors is large. To speed up vector search, we usually use index structures such as IVF (Inverted File Index), HNSW (Hierarchical Navigable Small World), etc. Through ANNs (Approximate Nearest Neighbors Search) algorithms, we can find the vector most similar to a given query vector with lower time complexity, such as O(log(n)). 3.3.1 #### LSH (Locality Sensitive Hashing) Locality Sensitive Hashing (LSH) works by processing each vector with a hash function, grouping vectors into buckets, thereby maximizing hash collisions, rather than minimizing collisions as usual hash functions do. Here is a diagram from Pinecone: The specific details of LSH are as follows: Shingling: Use k-shingling and one-hot encoding to convert text into sparse vectors. k-shingling means using a sliding window of size k to extract k consecutive characters from the text. one-hot encoding means comparing the result of k-shingling with the vocabulary, and if it exists, it is represented as 1 in the vocabulary, otherwise 0. Then use MinHash to create a ‚Äúsignature‚Äù. Create a random permutation of [1‚Ä¶len(voc)+1]. Use the value from top to bottom in the random permutation as the index. If the index-1 position of the original sparse vector is 1, take the index-1 position number of the random permutation as the signature value. Repeat n times to get an n-dimensional dense vector. Band and Hash Divide the n-dimensional signature vector into b groups, each with r elements. Hash each group to get b hash values. If two vectors have the same hash value, put them in the same bucket. If in the same bucket, consider them as candidate pairs. Here, as b increases, more candidate pairs are returned, which naturally leads to more false positives. This means that as the dimension increases, the possibility of false positives increases, and more hash buckets need to be maintained, which also increases storage overhead. Therefore, LSH is more suitable for low-dimensional vector search and is not the mainstream vector search algorithm. 3.3.2 IVFÔºàInverted File IndexÔºâ The inverted index algorithm is a simple, easy-to-understand, and very easy-to-implement algorithm, and it has a good search speed, but the search accuracy is worse than HNSW, but the memory consumption is relatively less than HNSW. The core of building an IVF index is divided into two steps: Use a clustering algorithm to divide the vectors into nlist clusters. Assign the vectors to the corresponding clusters. When searching, set the number of cells to search nprobe. The impact of the parameters here is: Increasing nlist will slow down the index building speed because the vectors need to be calculated with more centroids during the clustering process; at the same time, it will reduce the search time because there are fewer vectors corresponding to the centroids, making knn faster. Increasing nprobe will improve the recall rate but will reduce the search speed because more cells need to be searched. 3.3.3 HNSW (Hierarchical Navigable Small World) HNSW combines the advantages of NSW and Skip List and is an efficient vector search algorithm. The core idea of HNSW is to build a multi-layer graph, where each layer is a small world. By searching for the nearest nodes in each layer and then searching for the nearest nodes in the next layer, the vector most similar to the given query vector is finally found. NSW is based on a theory that the distance from any point to any other point on NSW is finite and can be found with a few jumps. The construction process of NSW: Randomly select a point as the insertion point. Find the m nearest points to the insertion point. Connect the insertion point with the m points. The randomness here will increase the number of long connections in the early graph, speeding up the se","date":"2024-07-13","objectID":"/en/vector-search/:3:3","tags":["vector search","Postgres"],"title":"The internals of Vector Databases","uri":"/en/vector-search/"},{"categories":["2024","vector search","Postgres"],"content":"3.4 Vector Search Algorithm Optimization By reducing the size of vectors or reducing dimensions to make searches faster, here are some common vector search algorithm optimization methods. 3.4.1 PQÔºàProduct QuantizationÔºâ Here I borrow a diagram from a Zhihu user, as the user's diagram is very well-drawn: Construction phase: First, split N original vectors into multiple sub-vectors. For example, a 256-dimensional vector is split into 8 32-dimensional sub-vectors. Then perform clustering in each sub-vector space, using clustering algorithms such as KMeans. Assuming there are 1024 clusters in each subspace, encode each cluster center to get 1024 IDs. Encode the original vectors into the nearest cluster center ID, and finally concatenate them. Retrieval phase: Split the retrieval vector. Calculate the distance between each subspace and each cluster center to create a distance table. Use the distance table to calculate the distance between the query and candidate samples in each subspace, accumulate them, and take the top-k. The splitting involved can be done in parallel. PQ is generally not used directly because it still requires a lot of distance calculations. Usually, IVF is first used to find the most promising top-k clusters, and then PQ is performed. 3.4.2 SQÔºàScalar QuantizationÔºâ SQ is relatively simple. Encoding: scalar = (max-min)/255, floor(value-min/scaler). If less than 0, take 0; if greater than 255, take 255. This compresses the vector to between 0-255, reducing the size of the vector but losing some information. Decoding: value = min + (code + 0.5)*(max-min)/255. 3.4.3 RabitQ RabitQ comes from the paper RaBitQ: Quantizing High-Dimensional Vectors with a Theoretical Error Bound for Approximate Nearest Neighbor Search. RabitQ points out two problems with the current PQ algorithm: Using the centroid of kmeans as the codebook is a heuristic approximation during construction, with no theoretical guarantee. Distance estimation, using the distance between the quantized vector and the query vector to estimate the distance between the original vector and the query vector, lacks an approximate error range. How to solve the above problems: Codebook construction phase First, normalize the data vectors to align them on the unit hypersphere in D-dimensional space. Construct a set of $2^{D}$ bivalued vectors with coordinates $‚àí1/\\sqrt{D}$ or $+1/\\sqrt{D}$ (i.e., the set consists of the vertices of a hypercube uniformly distributed on the unit hypersphere). Randomly rotate the bivalued vectors by multiplying each bivalued vector by a random orthogonal matrix (i.e., perform a Johnson-Lindenstrauss transformation). For each vector, take the closest vector in the codebook as the quantized vector. Since each quantized vector is a rotated D-dimensional bivalued vector, we represent its quantization code as a bit string of length D, where 0 and 1 represent two different values. The basic principle of codebook construction is that it has a clear geometric interpretation (i.e., the vectors in the codebook are a set of randomly rotated vectors on the unit hypersphere), allowing explicit analysis of the geometric relationships between data vectors, their quantized vectors, and query vectors. Distance estimation Carefully design an estimator for the distance between data vectors and query vectors based on the above geometric relationships, and prove that this estimator is unbiased and provides an error range. At the same time, when estimating distances, even with shorter quantization codes, about half of the advantages can be estimated with small empirical errors. RaBitQ‚Äôs distance estimatorÔºö Single data vector uses bitwise operations. Batch data uses SIMD acceleration. Using a random codebook avoids the poor performance of bivalued codebooks on specific vectors, such as ($1/\\sqrt{D}$‚Ä¶ $‚àí1/\\sqrt{D}$) and (1, 0, 0, 0). We multiply this codebook by a random orthogonal matrix, allowing the unit vectors of the codebook to have the same probability of","date":"2024-07-13","objectID":"/en/vector-search/:3:4","tags":["vector search","Postgres"],"title":"The internals of Vector Databases","uri":"/en/vector-search/"},{"categories":["2024","vector search","Postgres"],"content":"4. Common Vector Databases and Their Pros and Cons The following lists some common vector databases and their pros and cons. Some are dedicated vector databases, while others are extensions of existing relational databases. ","date":"2024-07-13","objectID":"/en/vector-search/:4:0","tags":["vector search","Postgres"],"title":"The internals of Vector Databases","uri":"/en/vector-search/"},{"categories":["2024","vector search","Postgres"],"content":"4.1 Milvus Milvus is an excellent open-source vector database that supports multiple vector search algorithms, including HNSW, DiskANN, IVF, etc. In addition to basic vector retrieval functions, it also provides sharding, streaming data ingestion, and hybrid search. Milvus adopts a cloud-native, shared-everything architecture with separate control and data planes. Each component is independent and horizontally scalable, including: Access Layer: Consists of a set of stateless proxies. It provides endpoints for user connections, verifies client requests, and merges and returns results. It uses load balancing components such as Nginx, Kubernetes Ingress, NodePort, and LVS to provide a unified service address. Since Milvus uses a massively parallel processing (MPP) architecture, the proxy aggregates and post-processes intermediate results and then returns the final results to the client. Coordinator Service: Responsible for assigning tasks to execution nodes, including root coord, data coord, and query coord. root coord: Handles data definition language (DDL) and data control language (DCL) requests, such as creating or deleting collections, partitions, or indexes, and managing TSO (Timestamp Oracle) and time ticker. data coord: Manages data and index node topology, maintains metadata, and triggers background data operations such as flush, compact, and index building. query coord: Manages query node topology, load balancing, and the conversion of growing segments to sealed segments. Worker Node: Executes tasks assigned by the coordinator service and proxy DML commands. Query Node: Retrieves incremental log data, converts it into growing segments by subscribing to the log broker, loads historical data from object storage, and performs hybrid searches between vector and scalar data. Data Node: Obtains incremental log data by subscribing to the log broker, processes mutation requests, and packages log data into log snapshots stored in object storage. Index Node: Builds indexes. Index nodes do not need to reside in memory and can be implemented through a Serverless framework. Storage Layer: Object storage is responsible for storing data, including data files and index files. Meta Storage: Meta storage stores metadata snapshots, such as collection schemas and message consumption checkpoints. Storing metadata requires high availability, strong consistency, and transaction support, so Milvus chooses etcd for meta storage. Milvus also uses etcd for service registration and health checks. Object Storage: Stores log snapshot files, index files for scalar and vector data, and intermediate query results. Milvus uses MinIO as object storage, which can be easily deployed on AWS S3 and Azure Blob. However, object storage has high access latency and charges based on query counts. To improve performance and reduce costs, Milvus plans to implement cold and hot data separation on a memory or SSD-based cache pool. Log Broker: A publish-subscribe system responsible for streaming data persistence and event notification. It also ensures the integrity of incremental data when worker nodes recover from system failures. Milvus cluster uses Pulsar as the log broker; Milvus standalone uses RocksDB as the log broker. Additionally, the log broker can be easily replaced with streaming data storage platforms such as Kafka. Milvus's cloud-native architecture is its advantage, but it also brings significant challenges to developers, such as learning new concepts and the operational management challenges brought by related components like Pulsar or etcd. ","date":"2024-07-13","objectID":"/en/vector-search/:4:1","tags":["vector search","Postgres"],"title":"The internals of Vector Databases","uri":"/en/vector-search/"},{"categories":["2024","vector search","Postgres"],"content":"4.4 Pinecone ","date":"2024-07-13","objectID":"/en/vector-search/:4:2","tags":["vector search","Postgres"],"title":"The internals of Vector Databases","uri":"/en/vector-search/"},{"categories":["2024","vector search","Postgres"],"content":"4.5 Qdrant ","date":"2024-07-13","objectID":"/en/vector-search/:4:3","tags":["vector search","Postgres"],"title":"The internals of Vector Databases","uri":"/en/vector-search/"},{"categories":["2024","vector search","Postgres"],"content":"4.6 Pgvector ","date":"2024-07-13","objectID":"/en/vector-search/:4:4","tags":["vector search","Postgres"],"title":"The internals of Vector Databases","uri":"/en/vector-search/"},{"categories":["2024","vector search","Postgres"],"content":"4.7 Pgvecto.rs ","date":"2024-07-13","objectID":"/en/vector-search/:4:5","tags":["vector search","Postgres"],"title":"The internals of Vector Databases","uri":"/en/vector-search/"},{"categories":["2024","vector search","Postgres"],"content":"4.8 VectorChord ","date":"2024-07-13","objectID":"/en/vector-search/:4:6","tags":["vector search","Postgres"],"title":"The internals of Vector Databases","uri":"/en/vector-search/"},{"categories":["2024","vector search","Postgres"],"content":"5. Excellent Vector Search Libraries and Open-Source Vector Database Projects ","date":"2024-07-13","objectID":"/en/vector-search/:5:0","tags":["vector search","Postgres"],"title":"The internals of Vector Databases","uri":"/en/vector-search/"},{"categories":["2024","vector search","Postgres"],"content":"6. What You Need to Know About Vector Database Commercialization ","date":"2024-07-13","objectID":"/en/vector-search/:6:0","tags":["vector search","Postgres"],"title":"The internals of Vector Databases","uri":"/en/vector-search/"},{"categories":["2024","vector search","Postgres"],"content":"7. Summary Here, I have briefly introduced some basic knowledge of vector search, as well as some common vector search algorithms, vector search application scenarios, vector search algorithm optimization, common vector databases and their pros and cons, excellent vector search libraries, and open-source vector database projects. I hope to apply this knowledge to actual scenarios in the future. I hope this article can help you better understand vector search. ","date":"2024-07-13","objectID":"/en/vector-search/:7:0","tags":["vector search","Postgres"],"title":"The internals of Vector Databases","uri":"/en/vector-search/"},{"categories":["2024","vector search","Postgres"],"content":"8. References Thank you very much to Pinecone's articles, which gave me a deeper understanding of vector databases. https://www.pinecone.io/learn/series/faiss/vector-indexes/ https://www.pinecone.io/learn/series/faiss/locality-sensitive-hashing/ https://zhuanlan.zhihu.com/p/379372268 https://songlinlife.github.io/2022/%E6%95%B0%E6%8D%AE%E5%BA%93/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9ANSG/ https://www.xiemingzhao.com/posts/hnswAlgo.html https://whenever5225.github.io/2020/05/11/hnsw-heuristic/ Search Engine For AIÔºöÈ´òÁª¥Êï∞ÊçÆÊ£ÄÁ¥¢Â∑•‰∏öÁ∫ßËß£ÂÜ≥ÊñπÊ°à https://zhuanlan.zhihu.com/p/50143204 https://mp.weixin.qq.com/s/AelU5O52Ed0Zx7f9867UNw ","date":"2024-07-13","objectID":"/en/vector-search/:8:0","tags":["vector search","Postgres"],"title":"The internals of Vector Databases","uri":"/en/vector-search/"},{"categories":null,"content":"About Far East","date":"2022-12-29","objectID":"/en/about/","tags":null,"title":"About xieydd","uri":"/en/about/"},{"categories":null,"content":"üì´ If you wish to contact me, you can send an email to xieydd@gmail.com, or add my WeChat echo -n 'eGlleWRkX2hhaGEK' | base64 -d. üíª As of 2024, I have over 6 years of experience in AI Infrastructure: ","date":"2022-12-29","objectID":"/en/about/:0:0","tags":null,"title":"About xieydd","uri":"/en/about/"},{"categories":null,"content":"2018-2021.2 (including internship) Unisound At the AI algorithm company Unisound, I was responsible for the development and operation of the Atlas supercomputing platform, supporting NLP and CV model training. Key responsibilities included: Developing a large-scale intelligent scheduling system to optimize multi-tenant resource allocation Enhancing the performance of the high-performance distributed file system Lustre Building a multi-layer cache cloud-native architecture to accelerate AI model training Worked on 8 Bit training and inference optimization at Unisound, optimizing models for NPU and NVIDIA Edge Devices. ","date":"2022-12-29","objectID":"/en/about/:0:1","tags":null,"title":"About xieydd","uri":"/en/about/"},{"categories":null,"content":"2021.2-2023.5 Tencent Cloud Developed a large-scale AI platform for public cloud: Built a high-performance, scalable elastic offline training platform using EKS (Elastic Kubernetes Service). Integrated public cloud object storage and the GooseFS accelerator to create a high-performance cache scheduling system on the cloud Established FinOps infrastructure to help public cloud customers manage and optimize cloud costs more effectively, enhancing cloud resource utilization: Optimized scheduling and rescheduling, identified high and low priority tasks, and implemented intelligent elastic scaling. Combined Tencent's Ruyi kernel scheduler optimization and observability to optimize costs while maintaining service quality Launched a large-scale cost reduction initiative in the internal cloud, improving resource utilization through efficient resource allocation ","date":"2022-12-29","objectID":"/en/about/:0:2","tags":null,"title":"About xieydd","uri":"/en/about/"},{"categories":null,"content":"2023.5-present Tensorchord Leading the development of the Serverless Inference platform ModelZ on GCP, providing optimized cold start model service inference: Reduced model service cold start time through cache model services and image preheating Implemented JuiceFS to build a high-performance cache scheduling system, enhancing model service performance Leading the Cloud Team, developing the vector database VectorChord's cloud service and customer support VectorChord Cloud: Built a vector database based on Postgres on AWS, achieving control and data plane separation, BYOC (Bring Your Own Cloud), BYOD (Bring Your Own Data) capabilities Implemented cloud-native architecture to achieve Postgres storage and compute separation, high availability, Backup, PITR (Point-In-Time Recovery), In-Place Upgrade features Skill set: Kubernetes, GCP, AWS, Kubeflow, FinOps, RAG, Vector Database, Storage Acceleration, Tensorflow, Pytorch, Cloud Native, MLOps, AI Infrastructure, etc. üå± Currently focusing on MLOps and FinOps, contributing to several open source projects: fluid Fluid, elastic data abstraction and acceleration for BigData/AI applications in the cloud. (Project under CNCF) crane Crane is a FinOps Platform for Cloud Resource Analytics and Economics in Kubernetes clusters. The goal is to help users manage cloud costs more easily while ensuring application quality. crane-scheduler Crane scheduler is a Kubernetes scheduler that can schedule pods based on actual node load. creator Creator is the brain of the crane project, containing the core algorithm module and evaluation module. openmodelz One-click machine learning deployment (LLM, text-to-image, etc.) at scale on any cluster (GCP, AWS, Lambda labs, your home lab, or even a single machine). clusternet [CNCF Sandbox Project] Managing your Kubernetes clusters (including public, private, edge, etc.) as easily as browsing the Internet vectorchord Scalable, fast, and disk-friendly vector search in Postgres, the successor of pgvecto.rs. ","date":"2022-12-29","objectID":"/en/about/:0:3","tags":null,"title":"About xieydd","uri":"/en/about/"}]